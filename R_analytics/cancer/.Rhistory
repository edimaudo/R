library(lattice)
library(readxl)
library(gridExtra)
library(dplyr)
library(tidyr)
library(ggpubr)
library(polycor)
hist(mydata_hist$last_evaluation,col="#FC4E07",
main = "Last evaluation", xlab="") + theme_minimal()
mydata_hist <- mydata %>% filter(mydata$left==1)
hist(mydata_hist$last_evaluation,col="#FC4E07",
main = "Last evaluation", xlab="") + theme_minimal()
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor(mydata_hist), method="color", col=col(200),
type="full",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag=TRUE
)
#correlation
corinfo <- mydata[,1:8]
corrplot(cor(corinfo))
corrplot(cor(corinfo), method="number")
#write.csv(corinfo, file="correlation.csv")
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor(corinfo), method="color", col=col(200),
type="full",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag=TRUE
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor(mydata_hist[,1:8]), method="color", col=col(200),
type="full",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag=TRUE
)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor(mydata_hist[,1:6,8]), method="color", col=col(200),
type="full",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag=TRUE
)
#correlation those who stayed
mydata_hist1 <- mydata %>% filter(mydata$left==0)
corrplot(cor(mydata_hist[,1:6,8]), method="color", col=col(200),
type="full",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag=TRUE
)
library(corrplot)
#correlation those who stayed
mydata_hist1 <- mydata %>% filter(mydata$left==0)
corrplot(cor(mydata_hist[,1:6,8]), method="color", col=col(200),
type="full",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag=TRUE
)
#libraries
library(psy)
library(nFactors)
library(MASS)
library(psych)
library(cluster)
library(ggplot2)
library(factoextra)
library(corrplot)
library(lattice)
library(readxl)
library(gridExtra)
library(dplyr)
library(tidyr)
library(ggpubr)
library(polycor)
#correlation those who stayed
mydata_hist1 <- mydata %>% filter(mydata$left==0)
corrplot(cor(mydata_hist[,1:6,8]), method="color", col=col(200),
type="full",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag=TRUE
)
hist(mydata_hist$Work_accident,col="#3090C7",
main = "Work accident", xlab="")
ggplot(mydata_hist,aes(x=sales))+geom_bar(fill="#FF00FF") +
xlab("Department")
library(ggplot2)
ggplot(mydata_hist,aes(x=sales))+geom_bar(fill="#FF00FF") +
xlab("Department")
plot(mydata_hist$salary,col="#009999", main = "Salary", xlab="") + theme_minimal()
ggplot(mydata_hist,aes(x=sales))+geom_bar(fill="#FF00FF") +
xlab("Department") + theme_classic()
ggplot(mydata_hist,aes(x=sales))+geom_bar(fill="#FF00FF") +
xlab("Department") + theme_dark()
ggplot(mydata_hist,aes(x=sales))+geom_bar(fill="#FF00FF") +
xlab("Department") + theme_grey()
library(ggplot2)
library(psy)
library(nFactors)
library(MASS)
library(psych)
library(cluster)
library(ggplot2)
library(factoextra)
library(corrplot)
library(lattice)
library(readxl)
library(gridExtra)
library(dplyr)
library(tidyr)
library(ggpubr)
library(polycor)
#==========================
#logistic regression
#==========================
#Clear old data
rm(list=ls())
#use filechooser to select csv file
mydata <- read.csv(file.choose(), sep = ',')
#Prepare data
mydata.orig = mydata #save orig data copy
mydata <- na.omit(mydata) # listwise deletion of missing
#mydata[1] <- NULL #remove the first column
#mydata <- scale(mydata) #scale data if needed
#set seed
set.seed(1)
#convert department and salary to factors
mydata$sales<-as.factor(data$sales)
mydata$salary<-as.factor(data$salary)
mydata$salary<-ordered(data$salary,levels=c("low","medium","high"))
#set seed
set.seed(1)
#convert department and salary to factors
mydata$sales<-as.factor(data$sales)
mydata$salary<-as.factor(data$salary)
mydata$salary<-ordered(data$salary,levels=c("low","medium","high"))
#set seed
set.seed(1)
#convert department and salary to factors
mydata$sales<-as.factor(mydata$sales)
mydata$salary<-as.factor(mydata$salary)
mydata$salary<-ordered(mydata$salary,levels=c("low","medium","high"))
install.packages("LogicReg")
install.packages("LogicReg")
#logistic regression model
ctrl <- trainControl(method = "cv", number = 5)
modelglm <- train(as.factor(left) ~. , mydata = trainSplit, method = "glm", trControl = ctrl)
summary(modelglm)
#prediction
predictors <- names(trainSplit)[names(trainSplit) != 'left']
predglm <- predict(modelglm, testSplit)
summary(predglm)
#confusion matrix
confusionMatrix(predglm, testSplit$left)
library(LogicReg)
#logistic regression model
ctrl <- trainControl(method = "cv", number = 5)
modelglm <- train(as.factor(left) ~. , mydata = trainSplit, method = "glm", trControl = ctrl)
summary(modelglm)
#prediction
predictors <- names(trainSplit)[names(trainSplit) != 'left']
predglm <- predict(modelglm, testSplit)
summary(predglm)
#confusion matrix
confusionMatrix(predglm, testSplit$left)
#logistic regression model
ctrl <- trainControl(method = "cv", number = 5)
modelglm <- train(as.factor(left) ~. , mydata = trainSplit, method = "glm", trControl = ctrl)
summary(modelglm)
ctrl <- trainControl(method = "cv", number = 5)
set.seed(1234)
library(caret)
#training and test data
splitIndex <- createDataPartition(mydata$left, p = .80,list = FALSE, times = 1)
trainSplit <- mydata[ splitIndex,]
testSplit <- mydata[-splitIndex,]
print(table(trainSplit$left))
ctrl <- trainControl(method = "cv", number = 5)
modelglm <- train(as.factor(left) ~. , mydata = trainSplit, method = "glm", trControl = ctrl)
summary(modelglm)
modelglm <- train(as.factor(left) ~. , mydata = trainSplit, method = "glm", trControl = ctrl)
modelglm <- train(as.factor(left) ~. , data = trainSplit, method = "glm", trControl = ctrl)
summary(modelglm)
predictors <- names(trainSplit)[names(trainSplit) != 'left']
predglm <- predict(modelglm, testSplit)
summary(predglm)
confusionMatrix(predglm, testSplit$left)
#people that stayed
mydata_stay <- mydata %>% filter(mydata$left==0)
hr_model <- mydata %>% filter(mydata$left==0)
gmlmodel <- train(left~., data=hr_model, trControl=train_control, method="LogitBoost")
# make predictions
predictions<- predict(gmlmodel,hr_model)
gmlmodelbinded <- cbind(hr_model,predictions)
# summarize results
confusionMatrix<- confusionMatrix(gmlmodelbinded$predictions,gmlmodelbinded$left)
confusionMatrix
#train model
gmlmodel <- train(left~., data=hr_model, trControl=train_control, method="LogitBoost")
# make predictions
predictions<- predict(gmlmodel,hr_model)
#people that stayed
gp <- mydata %>% filter(mydata$left==0)
#training & test data
splitIndex <- createDataPartition(gp$left, p = .80, list = FALSE, times = 1)
trainSplit <- gp[splitIndex,]
testSplit <- gp[-splitIndex,]
print(table(trainSplit$left))
gp <- mydata %>% filter(mydata$left==0)
splitIndex <- createDataPartition(gp$left, p = .80, list = FALSE, times = 1)
hr_model <- mydata %>% filter(mydata$left==0)
gmlmodel <- train(left~., data=hr_model, trControl=train_control, method="LogitBoost")
predictions<- predict(gmlmodel,hr_model)
library(caret)
mydata_stay <- mydata %>% filter(mydata$left==1)
View(mydata_stay)
mydata_stay <- mydata %>% filter(mydata$left==0)
View(mydata_stay)
mydata_stay$sales<-as.factor(mydata_stay$sales)
mydata_stay$salary<-as.factor(mydata_stay$salary)
mydata_stay$salary<-ordered(mydata_stay$salary,levels=c("low","medium","high"))
splitIndex1 <- createDataPartition(mydata_stay$left, p = .80,list = FALSE, times = 1)
trainSplit1 <- mydata_stay[ splitIndex1,]
testSplit1 <- mydata_stay[-splitIndex1,]
print(table(trainSplit1$left))
set.seed(1234)
splitIndex1 <- createDataPartition(mydata_stay$left, p = .80,list = FALSE, times = 1)
View(mydata_stay)
#training and test data
splitIndex <- createDataPartition(mydata$left, p = .80,list = FALSE, times = 1)
trainSplit <- mydata[ splitIndex,]
testSplit <- mydata[-splitIndex,]
print(table(trainSplit$left))
#logistic regression model
ctrl <- trainControl(method = "cv", number = 5)
modelglm <- train(as.factor(left) ~. , data = trainSplit, method = "glm", trControl = ctrl)
summary(modelglm)
#prediction
predictors <- names(trainSplit)[names(trainSplit) != 'left']
predglm <- predict(modelglm, testSplit)
summary(predglm)
#confusion matrix
confusionMatrix(predglm, testSplit$left)
View(mydata_stay)
confusionMatrix(predglm, testSplit$left)
summary(modelglm)
#This file contains monthly average electricity usage data in Iowa City from 1971 to 1979.
#questions
#1.	Fit a seasonal trigonometric regression model to the electricity usage data.
#Forecast the electricity price for January 1980 using the trigonometric regression model.
#2.	Describe in detail two ways of obtaining the seasonally adjusted electricity usage data.
#3.	Obtain the 3rd order moving average for the electricity price data.
#What is the forecast for April 1980 based on this moving average.
#4.	Using the average electricity usage as the initial value,
#obtain the next 2 first order exponentially smoothed values using a weight Î¸ of 0.6.
#Show the detailed calculations step-by-step.
#libraries
rm(list=ls())
#use filechooser to select csv file
iowadata <- read.csv(file.choose(), sep = ',')
#Prepare data
iowadata.orig = iowadata #save orig data copy
iowadata <- na.omit(iowadata) # listwise deletion of missing
View(iowadata)
summary(iowadata)
setwd("~/Documents/Coding/R/R_analytics/wine_kmc")
wine_data <- read_xlsx("WineKMC.xlsx",1)
wine_data <- read.xlsx("WineKMC.xlsx",1)
wine_data <- read.xlsx("WineKMC.xlsx",1)
library(xlsx)
wine_data <- read.xlsx("WineKMC.xlsx",1)
wine_data <- read.xlsx("WineKMC.xlsx",SheetName="Sheet1")
#libraries
library(readxl)
#clear old data
rm(list=ls())
#read excel file
wine_data <- read_excel("WineKMC.xlsx",sheets="sheet1")
wine_data <- read_excel("WineKMC.xlsx",sheet=1)
View(wine_data)
head(wine_data)
library(tibble)
library(tibble)
decision trees
ctrl <- trainControl(method = "cv", number = 5)
tbmodel <- train(as.factor(class) ~., data = trainSplit, method = "C5.0Tree", trControl = ctrl)
pred <- predict(tbmodel, testSplit)
confusionMatrix(pred,testSplit$class)
roc(testdata, prediction)
auc1 <- roc(as.numeric(testSplit$left), as.numeric(pred))
print(auc1)
plot(auc1, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc1$auc[[1]],3)),col = 'blue')
#cancer info
# #  Attribute                     Domain
# -- -----------------------------------------
# 1. Sample code number            id number
# 2. Clump Thickness               1 - 10
# 3. Uniformity of Cell Size       1 - 10
# 4. Uniformity of Cell Shape      1 - 10
# 5. Marginal Adhesion             1 - 10
# 6. Single Epithelial Cell Size   1 - 10
# 7. Bare Nuclei                   1 - 10
# 8. Bland Chromatin               1 - 10
# 9. Normal Nucleoli               1 - 10
# 10. Mitoses                      1 - 10
# 11. Class:                       (2 for benign, 4 for malignant)
#build model that can predict class
#libraries
library(caret)
library(corrplot)
library(ggplot2)
library(pROC)
library(LogicReg)
library(randomForest)
#data
data <- read.table("breast-cancer-wisconsin.data",header=F,sep=",",stringsAsFactors=F)
#summary
summary(data)
head(data)
#add column names
names(data) <- c('id','ct','ucsize','ucshape','ma','secs','bn','bc','nn','miti','class')
#clean data
require(stringr)
#remove whitespace
data <-t(apply(data, 1, function(x) {str_replace(x, "\\s+", "")}))
data <-t(apply(data, 1, function(x) {str_replace(x, "\\D", NA)}))
#convert from string to numeric
data <- as.data.frame(data, stringsAsFactors=F)
#but they're still characters!
sapply(data,mode)
#transform them back to numeric
#define function
to_numeric <- function(x) as.numeric(as.character(x))
data <- modifyList(data, lapply(data, to_numeric))
sapply(data,mode)
data.orig <- data
#remove NA
data <- na.omit(data)
#exploratory analysis
#correlation
corinfo <- data[,2:11]
corrplot(cor(corinfo), method="number")
data[1] <- NULL #drop the first column
#create training and test data
set.seed(1234)
splitIndex <- createDataPartition(data$class, p = .80,list = FALSE, times = 1)
trainSplit <- data[ splitIndex,]
testSplit <- data[-splitIndex,]
print(table(trainSplit$class))
setwd("~/Documents/Coding/R/R_analytics/cancer")
#cancer info
# #  Attribute                     Domain
# -- -----------------------------------------
# 1. Sample code number            id number
# 2. Clump Thickness               1 - 10
# 3. Uniformity of Cell Size       1 - 10
# 4. Uniformity of Cell Shape      1 - 10
# 5. Marginal Adhesion             1 - 10
# 6. Single Epithelial Cell Size   1 - 10
# 7. Bare Nuclei                   1 - 10
# 8. Bland Chromatin               1 - 10
# 9. Normal Nucleoli               1 - 10
# 10. Mitoses                      1 - 10
# 11. Class:                       (2 for benign, 4 for malignant)
#build model that can predict class
#libraries
library(caret)
library(corrplot)
library(ggplot2)
library(pROC)
library(LogicReg)
library(randomForest)
#data
data <- read.table("breast-cancer-wisconsin.data",header=F,sep=",",stringsAsFactors=F)
#summary
summary(data)
head(data)
#add column names
names(data) <- c('id','ct','ucsize','ucshape','ma','secs','bn','bc','nn','miti','class')
#clean data
require(stringr)
#remove whitespace
data <-t(apply(data, 1, function(x) {str_replace(x, "\\s+", "")}))
data <-t(apply(data, 1, function(x) {str_replace(x, "\\D", NA)}))
#convert from string to numeric
data <- as.data.frame(data, stringsAsFactors=F)
#but they're still characters!
sapply(data,mode)
#transform them back to numeric
#define function
to_numeric <- function(x) as.numeric(as.character(x))
data <- modifyList(data, lapply(data, to_numeric))
sapply(data,mode)
data.orig <- data
#remove NA
data <- na.omit(data)
#exploratory analysis
#correlation
corinfo <- data[,2:11]
corrplot(cor(corinfo), method="number")
data[1] <- NULL #drop the first column
#create training and test data
set.seed(1234)
splitIndex <- createDataPartition(data$class, p = .80,list = FALSE, times = 1)
trainSplit <- data[ splitIndex,]
testSplit <- data[-splitIndex,]
print(table(trainSplit$class))
summary(data)
#add column names
names(data) <- c('id','ct','ucsize','ucshape','ma','secs','bn','bc','nn','miti','class')
#data
data <- read.table("breast-cancer-wisconsin.data",header=F,sep=",",stringsAsFactors=F)
#add column names
names(data) <- c('id','ct','ucsize','ucshape','ma','secs','bn','bc','nn','miti','class')
#clean data
require(stringr)
#remove whitespace
data <-t(apply(data, 1, function(x) {str_replace(x, "\\s+", "")}))
data <-t(apply(data, 1, function(x) {str_replace(x, "\\D", NA)}))
#convert from string to numeric
data <- as.data.frame(data, stringsAsFactors=F)
#but they're still characters!
sapply(data,mode)
#transform them back to numeric
#define function
to_numeric <- function(x) as.numeric(as.character(x))
data <- modifyList(data, lapply(data, to_numeric))
sapply(data,mode)
data.orig <- data
#remove NA
data <- na.omit(data)
#correlation
corinfo <- data[,2:11]
corrplot(cor(corinfo), method="number")
data[1] <- NULL #drop the first column
#create training and test data
#add column names
names(data) <- c('id','ct','ucsize','ucshape','ma','secs','bn','bc','nn','miti','class')
#add column names
names(data) <- c('ct','ucsize','ucshape','ma','secs','bn','bc','nn','miti','class')
set.seed(1234)
splitIndex <- createDataPartition(data$class, p = .80,list = FALSE, times = 1)
trainSplit <- data[ splitIndex,]
testSplit <- data[-splitIndex,]
print(table(trainSplit$class))
ctrl <- trainControl(method = "cv", number = 5)
tbmodel <- train(as.factor(class) ~., data = trainSplit, method = "C5.0Tree", trControl = ctrl)
tbmodel <- train(as.factor(class) ~., data = trainSplit, method = "C5.0Tree", trControl = ctrl)
pred <- predict(tbmodel, testSplit)
confusionMatrix(pred,testSplit$class)
roc(testdata, prediction)
auc1 <- roc(as.numeric(testSplit$left), as.numeric(pred))
auc1 <- roc(as.numeric(testSplit$class), as.numeric(pred))
print(auc1)
plot(auc1, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc1$auc[[1]],3)),col = 'blue')
aucdt <- roc(as.numeric(testSplit$class), as.numeric(pred))
print(aucdt)
#compare ROC curves
plot(aucrf, ylim=c(0,1), main=paste('ROC Comparison : RF(blue),decision tree(green),Logistic(Red)'),col = 'blue')
par(new = TRUE)
plot(aucglm,col = "red")
plot(aucdt,col="green")
#logistic regression
ctrl <- trainControl(method = "cv", number = 5)
modelglm <- train(as.factor(class) ~. , data = trainSplit, method = "glm", trControl = ctrl)
summary(modelglm)
### predict
predictors <- names(trainSplit)[names(trainSplit) != 'class']
predglm <- predict(modelglm, testSplit)
summary(predglm)
### score prediction using AUC
confusionMatrix(predglm, testSplit$class)
aucglm <- roc(as.numeric(testSplit$class), as.numeric(predglm),  ci=TRUE)
plot(aucglm, ylim=c(0,1), print.thres=TRUE,
main=paste('Logistic Regression AUC:',round(aucglm$auc[[1]],3)),col = 'blue')
#compare ROC curves
plot(aucrf, ylim=c(0,1), main=paste('ROC Comparison : RF(blue),decision tree(green),Logistic(Red)'),col = 'blue')
par(new = TRUE)
plot(aucglm,col = "red")
plot(aucdt,col="green")
#random forests
modelrf <- randomForest(as.factor(class) ~. , data = trainSplit)
importance(modelrf)
### predict
predrf <- predict(modelrf,testSplit)
summary(predrf)
### score prediction using AUC
confusionMatrix(predrf,testSplit$class)
aucrf <- roc(as.numeric(testSplit$class), as.numeric(predrf),  ci=TRUE)
plot(aucrf, ylim=c(0,1), print.thres=TRUE,
main=paste('Random Forest AUC:',round(aucrf$auc[[1]],3)),col = 'blue')
#compare ROC curves
plot(aucrf, ylim=c(0,1), main=paste('ROC Comparison : RF(blue),decision tree(green),Logistic(Red)'),col = 'blue')
par(new = TRUE)
plot(aucglm,col = "red")
plot(aucdt,col="green")
#compare ROC curves
plot(aucrf, ylim=c(0,1), main=paste('ROC Comparison : RF(blue),decision tree(green),Logistic(Red)'),col = 'blue')
par(new = TRUE)
plot(aucglm,col = "red")
par(new = TRUE)
plot(aucdt,col="green")
