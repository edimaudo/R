df_train_new <- cbind(as.data.frame(df_train_cat_new),Target)
df_train_new <- as.data.frame(df_train_new)
fit.rf <- train(Target~., data=df_train_new, method="rf", trControl=control)
typeof(df_train_new)
df_train_new <- data.frame(df_train_new)
#cross fold validation
control <- trainControl(method="repeatedcv", number=10, repeats=5)
#random forest
fit.rf <- train(Target~., data=df_train_new, method="rf", trControl=control)
fit.rf <- caret::train(Target~., data=df_train_new, method="rf", trControl=control)
LIBRARY(glmnet)
library(glmnet)
y <- train$target
tr <- train[,1:24]
tre <- rbind(tr,test)
tre <- tre %>%
mutate(month = as.character(month),
day = as.character(day),
ord_0 = as.character(ord_0),
bin_2 = as.character(bin_2),
bin_1 = as.character(bin_1),
bin_0 = as.character(bin_0))
tre_0 <- sparse.model.matrix(~. ,data=tre[,2:24])
tre_0 <- tre_0[,2:16530]
pf_0 <- colSums(tre_0)
tre_0<- tre_0[,pf_0>5]
tr_0 <- tre_0[1:nrow(tr),]
te_0 <- tre_0[(nrow(tr)+1):(nrow(tr)+nrow(test)),]
pf <- colSums(tr_0)
set.seed(1234)
m_cv <- cv.glmnet(tr_0,y, family = "binomial",type.measure = "auc",alpha=0,
standardize = F, lambda=seq(0.000035,0.000030,-0.0000002),
penalty.factor=(1/pf)^0.1, thresh = 1e-10, maxit = 1e9)
pr <- predict(m_cv$glmnet.fit, te_0, s= m_cv$lambda.min * 0.9,  type = "response")
colnames(pr) <- "target"
submission <- data.frame(id = tes$id, target = pr, row.names = NULL)
submission <- data.frame(id = test$id, target = pr, row.names = NULL)
write.csv(submission, file="submission_glmnet.csv", row.names = FALSE)
#remove old data
rm(list=ls())
#packages
packages <- c('ggplot2', 'corrplot','tidyverse','caret','mlbench','mice', 'caTools',
'dummies','stringr','forcats')
#load packages
for (package in packages) {
if (!require(package, character.only=T, quietly=T)) {
install.packages(package)
library(package, character.only=T)
}
}
#remove old data
rm(list=ls())
#packages
packages <- c('ggplot2', 'corrplot','tidyverse','caret','mlbench','mice',
'caTools','dummies','ggfortify)')
#load packages
for (package in packages) {
if (!require(package, character.only=T, quietly=T)) {
install.packages(package)
library(package, character.only=T)
}
}
users <- read_csv("BX-Users_clean.csv")
books <- read_csv("BX-Books_clean.csv")
ratings <- read_csv("BX-Book-Ratings_clean.csv")
setwd("~/Documents/Coding/R/shiny/bookRecommender")
#remove old data
rm(list=ls())
#packages
packages <- c('ggplot2', 'corrplot','tidyverse','caret','mlbench','mice',
'caTools','dummies','ggfortify)')
#load packages
for (package in packages) {
if (!require(package, character.only=T, quietly=T)) {
install.packages(package)
library(package, character.only=T)
}
}
users <- read_csv("BX-Users_clean.csv")
books <- read_csv("BX-Books_clean.csv")
ratings <- read_csv("BX-Book-Ratings_clean.csv")
View(books)
View(ratings)
users <- read_csv("BX-Users_clean.csv")
View(users)
View(ratings)
View(books)
install.packages("shinythemes")
shiny::runApp()
runApp('Documents/Coding/R/shiny/bookRecommender')
runApp('Documents/Coding/R/shiny/bookRecommender')
runApp('Documents/Coding/R/shiny/bookRecommender')
runApp('Documents/Coding/R/shiny/bookRecommender')
shiny::runApp('Documents/Coding/R/shiny/bookRecommender')
runApp('Documents/Coding/R/shiny/bookRecommender')
runApp('Documents/Coding/R/shiny/bookRecommender')
runApp('Documents/Coding/R/shiny/bookRecommender')
install.packages ("pwr")
library (pwr)
######## 2-sample test for equality of proportions ############
prop.test(c (225, 250), c (3450, 3000))
install.packages (“bayesAB”)
library (bayesAB)
######## 2-sample test for equality of proportions ############
prop.test(c (225, 250), c (3450, 3000))
A_binom <- rbinom (3450, 1, 0.065)
B_binom <- rbinom (3000, 1, 0.083)
plotBeta (1, 1)
plotBeta (100, 200) ## more specific range of p
AB1 <- bayesTest (A_binom, B_binom,
priors = c ('alpha' = 1, 'beta' = 1),
distribution = 'bernoulli')
AB2 <- bayesTest (A_binom, B_binom,
priors = c ('alpha' = 100,'beta' = 200),
distribution = 'bernoulli')
install.packages (“bayesAB”)
library (bayesAB)
uniqueTitle <- unique(books$bookTitle)
uniqueAuthor <- unique(books$bookAuthor)
uniquePublisher <- unique(books$publisher)
uniqueYear <- unique(books$yearOfPublication)
View(books)
View(ratings)
View(users)
View(books)
shiny::runApp('Documents/Coding/R/shiny/bookRecommender')
runApp('Documents/Coding/R/shiny/bookRecommender')
View(books)
View(ratings)
bookRating <- ratings %>%
inner_join(books,by = "ISBN")
View(bookRating)
bookRating <- ratings %>%
inner_join(books,by = "ISBN") %>%
select (bookTitle, bookRating)
View(bookRating)
#aggregate book ratings
bookRating2 <- bookRating %>%
group_by(bookTitle) %>%
summarise(bookRatingTotal = sum(bookRating))
View(bookRating2)
#aggregate book ratings
bookRating2 <- bookRating %>%
group_by(bookTitle) %>%
summarise(bookRatingTotal = average(bookRating))
#aggregate book ratings
bookRating2 <- bookRating %>%
group_by(bookTitle) %>%
summarise(bookRatingTotal = mean(bookRating))
View(bookRating2)
#aggregate book ratings
bookRating2 <- bookRating %>%
group_by(bookTitle) %>%
summarise(bookRatingTotal = sum(bookRating), n=n())
View(bookRating2)
bookRating2$AverageRate <- bookRating2$bookRatingTotal/bookRating2$n
View(bookRating2)
bookRating <- ratings %>%
inner_join(books,by = "ISBN") %>%
select (bookTitle, bookAuthor, bookRating)
#aggregate book ratings
bookRating2 <- bookRating %>%
group_by(bookTitle, bookAuthor) %>%
summarise(bookRatingTotal = sum(bookRating), n=n())
View(bookRating2)
bookRating2$AverageRate <- bookRating2$bookRatingTotal/bookRating2$n
View(bookRating2)
#top 5 book ratings visualization
p<-ggplot(data=bookRating2, aes(x=bookAuthor, y=AverageRate)) +
geom_bar(stat="identity")
# Horizontal bar plot
p + coord_flip()
bookRatingTop5 <- bookRating2 %>% top_n(5)
#top 5 book ratings visualization
p<-ggplot(data=bookRatingTop5, aes(x=bookAuthor, y=AverageRate)) +
geom_bar(stat="identity")
# Horizontal bar plot
p + coord_flip()
View(bookRatingTop5)
View(bookRating2)
bookRatingTop5 <- bookRating2 %>%
select(bookTitle, bookAuthor, AverageRate) %>%
tally(AverageRate) %>%
top_n(5)
View(bookRatingTop5)
bookRatingTop5 <- bookRating2 %>%
select(bookTitle, bookAuthor, AverageRate) %>%
arrange(desc(AverageRate)) %>%
top_n(5)
View(bookRatingTop5)
bookRatingTop5 %>% top_n(5)
bookRatingTop5 <- bookRatingTop5 %>% top_n(5)
bookRatingTop5 <- bookRating2 %>%
arrange(desc(AverageRate)) %>%
select(bookTitle, bookAuthor, AverageRate) %>%
top_n(5)
bookRatingTop5 <- bookRating2 %>%
arrange(desc(AverageRate)) %>%
top_n(5) %>%
select(bookTitle, bookAuthor, AverageRate)
bookRatingTop5 <- bookRating2 %>%
arrange(desc(AverageRate)) %>%
head(n = 10L) %>%
select(bookTitle, bookAuthor, AverageRate)
View(bookRatingTop5)
#top 5 book ratings visualization
p<-ggplot(data=bookRatingTop, aes(x=bookTitle, y=AverageRate)) +
geom_bar(stat="identity")
# Horizontal bar plot
p + coord_flip()
bookRatingTop <- bookRating2 %>%
arrange(desc(AverageRate)) %>%
head(n = 10L) %>%
select(bookTitle, bookAuthor, AverageRate) %>%
#top 5 book ratings visualization
p<-ggplot(data=bookRatingTop, aes(x=bookTitle, y=AverageRate)) +
geom_bar(stat="identity")
# Horizontal bar plot
p + coord_flip()
bookRatingTop <- bookRating2 %>%
arrange(desc(AverageRate)) %>%
head(n = 10L) %>%
select(bookTitle, bookAuthor, AverageRate)
#top 5 book ratings visualization
p<-ggplot(data=bookRatingTop, aes(x=bookTitle, y=AverageRate)) +
geom_bar(stat="identity")
# Horizontal bar plot
p + coord_flip()
bookPublishing <- books %>%
select (bookAuthor, yearOfPublication) %>%
group_by(yearOfPublication) %>%
tally()
View(bookPublishing)
bookPublishing <- books %>%
select (bookAuthor, yearOfPublication) %>%
group_by(bookAuthor,yearOfPublication) %>%
tally() %>%
arrange(desc(n)) %>%
head(n = 10L)
View(bookPublishing)
p<-ggplot(data=bookPublishing, aes(x=yearOfPublication, y=n)) +
geom_bar(stat="identity")
p
View(users)
View(ratings)
bookAge <- ratings %>%
inner_join(books, by="ISBN") %>%
inner_join(users, by="userID") %>%
select(bookAuthor, Age)
View(bookAge)
# Basic histogram
ggplot(bookAge, aes(x=Age)) + geom_histogram()
# Change the width of bins
# Basic histogram
ggplot(bookAge, aes(x=Age)) + geom_histogram()
# Change the width of bins
ggplot(df, aes(x=weight)) +
geom_histogram(binwidth=1)
# Change the width of bins
ggplot(bookAge, aes(x=Age)) +
geom_histogram(binwidth=1)
# Basic histogram
ggplot(bookAge, aes(x=Age)) + geom_histogram()
# Change the width of bins
ggplot(bookAge, aes(x=Age)) +
geom_histogram(binwidth=10)
ggplot(bookAge, aes(x=Age)) +
geom_histogram(binwidth=25)
bookLocation <- ratings %>%
inner_join(books, by="ISBN") %>%
inner_join(users, by="userID") %>%
select(bookAuthor, Location)
View(bookLocation)
bookLocation2 <- separate(bookLocation, Location,
into = c("area", "location","country"), sep = 3)
bookLocation2 <- separate(bookLocation, Location,
into = c("area", "location","country"), sep = 2)
bookLocation2 <- separate(bookLocation, Location,
into = c("area", "location","country"), sep = ",")
View(bookLocation2)
View(bookLocation2)
bookLocation3 <- bookLocation2 %>%
group_by(bookAuthor, country) %>%
tally()
View(bookLocation3)
shiny::runApp('Documents/Coding/R/shiny/KaggleSurvey')
shiny::runApp('Documents/Coding/R/shiny/KaggleSurvey')
#
# This is a Shiny web application that uses the Kaggle 2019 Data
# Science and Machine learning survery
#
#remove old data
#rm(list=ls())
#packages
packages <- c('ggplot2', 'corrplot','tidyverse','caret','mlbench','mice',
'caTools','dummies','ggfortify','shiny')
#load packages
for (package in packages) {
if (!require(package, character.only=T, quietly=T)) {
install.packages(package)
library(package, character.only=T)
}
}
#load data
multipleChoice <- read_csv("multiple_choice_responses.csv")
otherText <- read_csv("other_text_responses.csv")
questions <- read_csv("questions_only.csv")
surveySchema<- read_csv("survey_schema.csv")
shiny::runApp('Documents/Coding/R/shiny/KaggleSurvey')
runApp('Documents/Coding/R/shiny/KaggleSurvey')
#
# This is a Shiny web application that uses the Kaggle 2019 Data
# Science and Machine learning survery
#
#remove old data
#rm(list=ls())
#packages
packages <- c('ggplot2', 'corrplot','tidyverse','caret','mlbench','mice',
'caTools','dummies','ggfortify','shiny','countrycode','highcharter')
#load packages
for (package in packages) {
if (!require(package, character.only=T, quietly=T)) {
install.packages(package)
library(package, character.only=T)
}
}
#load data
multipleChoice <- read_csv("multiple_choice_responses.csv")
#otherText <- read_csv("other_text_responses.csv")
#questions <- read_csv("questions_only.csv")
#surveySchema<- read_csv("survey_schema.csv")
responses <- multipleChoice %>%
slice(2:n()) %>%
rename("duration" = `Time from Start to Finish (seconds)`) %>%
mutate(Q3 = str_replace_all(Q3,
c("United Kingdom of Great Britain and Northern Ireland" = "UK" ,
"United States of America" = "USA",
"Hong Kong \\(S\\.A\\.R\\.\\)" = "Hong Kong",
"Iran, Islamic Republic of..." = "Iran")))
setwd("~/Documents/Coding/R/shiny/KaggleSurvey")
#
# This is a Shiny web application that uses the Kaggle 2019 Data
# Science and Machine learning survery
#
#remove old data
#rm(list=ls())
#packages
packages <- c('ggplot2', 'corrplot','tidyverse','caret','mlbench','mice',
'caTools','dummies','ggfortify','shiny','countrycode','highcharter')
#load packages
for (package in packages) {
if (!require(package, character.only=T, quietly=T)) {
install.packages(package)
library(package, character.only=T)
}
}
#load data
multipleChoice <- read_csv("multiple_choice_responses.csv")
#otherText <- read_csv("other_text_responses.csv")
#questions <- read_csv("questions_only.csv")
#surveySchema<- read_csv("survey_schema.csv")
responses <- multipleChoice %>%
slice(2:n()) %>%
rename("duration" = `Time from Start to Finish (seconds)`) %>%
mutate(Q3 = str_replace_all(Q3,
c("United Kingdom of Great Britain and Northern Ireland" = "UK" ,
"United States of America" = "USA",
"Hong Kong \\(S\\.A\\.R\\.\\)" = "Hong Kong",
"Iran, Islamic Republic of..." = "Iran")))
#country info
#countr
View(responses)
unique(responses$Q15)
runApp()
unique(responses$Q10)
salaryinfo <- as.data.frame(unique(responses$Q10))
salaryinfo <- salaryinfo %>% arrange(desc(salaryinfo))
View(salaryinfo)
salaryInfo <- NULL
runApp()
salaryinfo <- responses %>%
select(Q10) %>%
group_by(Q10) %>%
summarise(freq = n())
salaryinfo <- na.omit(salaryinfo)
View(salaryinfo)
salaryinfo <- NULL
unique(responses$Q6)
unique(responses$Q7)
unique(responses$Q11)
unique(responses$Q10)
edlearn <- responses %>%
select(starts_with("Q9_P"), Q10) %>%
filter(Q10 %in% c("200,000-249,999", "250,000-299,999", "300,000-500,000", "> $500,000")) %>%
pivot_longer(starts_with("Q9_P"), values_to = "Activities") %>%
drop_na() %>%
select(-Q10, -name) %>%
group_by(Activities) %>%
summarize(freq = n())
edlearn <- responses %>%
select(starts_with("Q9_P"), Q10)
View(edlearn)
View(edlearn)
edlearn <- responses %>%
select(starts_with("Q9_P")) %>%
pivot_longer(starts_with("Q9_P"), values_to = "Activities") %>%
drop_na() %>%
group_by(Activities) %>%
summarize(freq = n()) %>%
edlearn <- responses %>%
select(starts_with("Q9_P")) %>%
pivot_longer(starts_with("Q9_P"), values_to = "Activities") %>%
drop_na() %>%
group_by(Activities) %>%
summarize(freq = n())
#packages
packages <- c('ggplot2', 'corrplot','tidyverse','caret','mlbench','mice',
'caTools','dummies','ggfortify','shiny','countrycode','highcharter',"tidyr")
#load packages
for (package in packages) {
if (!require(package, character.only=T, quietly=T)) {
install.packages(package)
library(package, character.only=T)
}
}
edlearn <- responses %>%
select(starts_with("Q9_P")) %>%
pivot_longer(starts_with("Q9_P"), values_to = "Activities") %>%
drop_na() %>%
group_by(Activities) %>%
summarize(freq = n())
edlearn <- responses %>%
select(starts_with("Q9_P"), Q10) %>%
#filter(Q10 %in% c("200,000-249,999", "250,000-299,999", "300,000-500,000", "> $500,000")) %>%
pivot_longer(starts_with("Q9_P"), values_to = "Activities") %>%
drop_na() %>%
select(-Q10, -name) %>%
group_by(Activities) %>%
summarize(freq = n())
edlearn <- responses %>%
select(starts_with("Q9_P"), Q10) %>%
#filter(Q10 %in% c("200,000-249,999", "250,000-299,999", "300,000-500,000", "> $500,000")) %>%
tidyr::pivot_longer(starts_with("Q9_P"), values_to = "Activities") %>%
drop_na() %>%
select(-Q10, -name) %>%
group_by(Activities) %>%
summarize(freq = n())
edlearn <- NULL
edlearn <- responses %>%
select(starts_with("Q9_P"), Q10) %>%
#filter(Q10 %in% c("200,000-249,999", "250,000-299,999", "300,000-500,000", "> $500,000")) %>%
tidyverse::pivot_longer(starts_with("Q9_P"), values_to = "Activities") %>%
drop_na() %>%
select(-Q10, -name) %>%
group_by(Activities) %>%
summarize(freq = n())
edlearn <- responses %>%
select(starts_with("Q9_P"), Q10) %>%
#filter(Q10 %in% c("200,000-249,999", "250,000-299,999", "300,000-500,000", "> $500,000")) %>%
pivot_longer(starts_with("Q9_P"), values_to = "Activities") %>%
drop_na() %>%
select(-Q10, -name) %>%
group_by(Activities) %>%
summarize(freq = n())
install.packages("tidyr")
install.packages('tidyr')
edlearn <- responses %>%
select(starts_with("Q9_P"), Q10) %>%
#filter(Q10 %in% c("200,000-249,999", "250,000-299,999", "300,000-500,000", "> $500,000")) %>%
pivot_longer(starts_with("Q9_P"), values_to = "Activities") %>%
drop_na() %>%
select(-Q10, -name) %>%
group_by(Activities) %>%
summarize(freq = n())
#
# This is a Shiny web application that uses the Kaggle 2019 Data
# Science and Machine learning survery
#
#remove old data
#rm(list=ls())
#packages
packages <- c('ggplot2', 'corrplot','tidyverse','caret','mlbench','mice',
'caTools','dummies','ggfortify','shiny','countrycode','highcharter',"tidyr")
#load packages
for (package in packages) {
if (!require(package, character.only=T, quietly=T)) {
install.packages(package)
library(package, character.only=T)
}
}
#load data
multipleChoice <- read_csv("multiple_choice_responses.csv")
#otherText <- read_csv("other_text_responses.csv")
#questions <- read_csv("questions_only.csv")
#surveySchema<- read_csv("survey_schema.csv")
responses <- multipleChoice %>%
slice(2:n()) %>%
rename("duration" = `Time from Start to Finish (seconds)`) %>%
mutate(Q3 = str_replace_all(Q3,
c("United Kingdom of Great Britain and Northern Ireland" = "UK" ,
"United States of America" = "USA",
"Hong Kong \\(S\\.A\\.R\\.\\)" = "Hong Kong",
"Iran, Islamic Republic of..." = "Iran")))
edlearn <- responses %>%
select(starts_with("Q9_P"), Q10) %>%
#filter(Q10 %in% c("200,000-249,999", "250,000-299,999", "300,000-500,000", "> $500,000")) %>%
pivot_longer(starts_with("Q9_P"), values_to = "Activities") %>%
drop_na() %>%
select(-Q10, -name) %>%
group_by(Activities) %>%
summarize(freq = n())
runApp()
